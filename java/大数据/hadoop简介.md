hadoop是一个开源的分布式处理框架，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的。
hadoop擅长日志分析

分布式计算的核心就在于 利用分布式算法 把运行在单台机器上的程序扩展到多台机器上并行运行.从而使数据处理能力成倍增加.但是这种分布式计算一般对编程人员要求很高,而且对服务器也有要求.导致了成本变得非常高.
Haddop 就是为了解决这个问题诞生的.Haddop 可以很轻易的把 很多linux的廉价pc 组成 分布式结点,然后编程人员也不需要知道分布式算法之类,只需要根据mapreduce的规则定义好接口方法,剩下的就交给Haddop. 它会自动把相关的计算分布到各个结点上去,然后得出结果.

例如上述的例子 ： Hadoop 要做的事 首先把 1PB的数据文件导入到 HDFS中, 然后编程人员定义好 map和reduce, 也就是把文件的行定义为key,每行的内容定义为value , 然后进行正则匹配,匹配成功则把结果 通过reduce聚合起来返回.Hadoop 就会把这个程序分布到N 个结点去并行的操作.
那么原本可能需要计算好几天,在有了足够多的结点之后就可以把时间缩小到几小时之内.

“Hadoop能做什么？” ，概括如下：

1、搜索引擎（Doug Cutting  设计Hadoop的初衷，为了针对大规模的网页快速建立索引）。

2、大数据存储，利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。

3、大数据处理，利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。

4、科学研究，Hadoop是一种分布式的开源框架，对于分布式计算有很大程度地参考价值。

 